{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LSTM1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GrLjLmlcHGgY"},"source":["Initialize notebook"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U69VEyzU2ZOt","executionInfo":{"status":"ok","timestamp":1617044153750,"user_tz":-120,"elapsed":52020,"user":{"displayName":"oldragon ar","photoUrl":"","userId":"11831130061906073290"}},"outputId":"ece9cfec-ed27-4e24-b7f1-00068a877890"},"source":["# Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","drive_folder = '/content/drive/My Drive/PAi 15/'\n","\n","# Import packages\n","\n","!pip install bert-for-tf2\n","\n","import numpy as np\n","\n","import sys\n","sys.path.insert(0, drive_folder + 'Data part')\n","sys.path.insert(0, drive_folder + 'Sentiment/Code pour lancer un modele')\n","\n","from read_file import dataframe_from_mult_files\n","from sentiment_file_manager import save_sentiments\n","from clean_text1 import clean_text\n","import Load_Model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n","Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.4MB/s \n","\u001b[?25hCollecting py-params>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n","Collecting params-flow>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp37-none-any.whl size=30535 sha256=c8fb493ff02857ecd534b852ced683c6c2869a2d3876917a8b2e414ba06c3b3f\n","  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.10.2-cp37-none-any.whl size=7912 sha256=49d3eda55a0bd7cc1f9c5d7eba5ca8e8cc1aa826e2714a6c6a45dbd8fe105046\n","  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-cp37-none-any.whl size=19472 sha256=03792a4858c8b80c6f96db78c3aed313710ea6edeffa1f63f7cec241f16261f2\n","  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tEw_uuLIjlEJ"},"source":["Load model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJCTA5yXcqvI","outputId":"ba7e7f6f-43c1-498e-d46d-6b2d82c2f4f1"},"source":["Load_Model.charge_model(drive_folder + \"Sentiment/Code pour lancer un modele/model_Tweets_Flights\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qTJonJ65G-18"},"source":["Load tweets"]},{"cell_type":"code","metadata":{"id":"Z1g1cpJFkMOY"},"source":["# tweets_filename = 'stream_tweets_587k'\n","# tweets_filename = 'All_tweets_231k'\n","tweets_filename = 'stream_tweets_Week4_181k'\n","tweets = dataframe_from_mult_files([drive_folder + 'Dataset/' + tweets_filename + '.csv'])\n","texts = [clean_text(text) for text in tweets.text]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YK5jsHk2HQTD"},"source":["Get sentiments"]},{"cell_type":"code","metadata":{"id":"veYEEMgWkzcG"},"source":["sentiments = Load_Model.evaluate_sentiment(texts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LPOrn0W20BwN"},"source":["Adjust sentiments in [-1, 0, 1]"]},{"cell_type":"code","metadata":{"id":"CVnzcaSpzVz4"},"source":["sentiments = np.array(sentiments) - 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7w4DlCn3tANW"},"source":["Save sentiments"]},{"cell_type":"code","metadata":{"id":"KaLKHqTstBuD"},"source":["save_sentiments(\n","    sentiments = sentiments,\n","    folder_name = drive_folder + 'Dataset/Sentiments/',\n","    tweets_filename = tweets_filename,\n","    model_name = 'LSTM1'\n",")"],"execution_count":null,"outputs":[]}]}