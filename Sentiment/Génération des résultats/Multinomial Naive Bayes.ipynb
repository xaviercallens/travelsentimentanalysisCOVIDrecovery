{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcjMHKzOW8Ep"
   },
   "source": [
    "Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40490,
     "status": "ok",
     "timestamp": 1616511220181,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "mXFMtc0FSbLg",
    "outputId": "1982cc5f-6450-41cc-a39a-c84bd95a9ae8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "root_folder = '/home/jupyter/travelsentimentanalysisCOVIDrecovery/'\n",
    "\n",
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from read_file import dataframe_from_mult_files\n",
    "from s_file_manager import save_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2xX9-TvaBMU"
   },
   "source": [
    "Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1616511246039,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "kLupVE9KZ7kk"
   },
   "outputs": [],
   "source": [
    "def shuffle_list(*ls):\n",
    "    l =list(zip(*ls))\n",
    "    shuffle(l)\n",
    "    return zip(*l)\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gM1gcMJfXmoj"
   },
   "source": [
    "Load training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20318,
     "status": "ok",
     "timestamp": 1616503234587,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "3riGriMOXm-L",
    "outputId": "d9ef1983-5399-4893-a097-56528fcc87f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de Reviews :156060\n"
     ]
    }
   ],
   "source": [
    "# trainset = pd.read_csv(drive_folder + '/Sentiment/train.tsv.zip', sep=\"\\t\")\n",
    "\n",
    "# rev0=trainset['Phrase']\n",
    "# sentiment0=trainset[\"Sentiment\"]\n",
    "# #y=to_categorical(movie_reviews.Sentiment.values)\n",
    "# print(\"Nombre total de Reviews :\"+ str(len(sentiment0)))\n",
    "\n",
    "# rev,sentiment=shuffle_list(rev0,sentiment0)\n",
    "\n",
    "# # On re-equilible la base de données : on doit remove 35000 'neutral'\n",
    "# n=79582-35000\n",
    "# k=0\n",
    "# y0=[]\n",
    "# reviews0=[]\n",
    "# for i in range(len(sentiment)):\n",
    "#   el=sentiment[i]\n",
    "#   if el==0 : \n",
    "#     y0.append(0)\n",
    "#     reviews0.append(rev[i])\n",
    "#   if el==1 :\n",
    "#     y0.append(1)\n",
    "#     reviews0.append(rev[i])\n",
    "#   if el==2 and k<n:\n",
    "#     k+=1 \n",
    "#     y0.append(2)\n",
    "#     reviews0.append(rev[i])\n",
    "#   if el==3 :\n",
    "#     y0.append(3)\n",
    "#     reviews0.append(rev[i])\n",
    "#   if el==4 :\n",
    "#     y0.append(4)\n",
    "#     reviews0.append(rev[i])\n",
    "\n",
    "# y_train=np.array(y0,dtype='float32')\n",
    "# X_train=np.array(reviews0)\n",
    "\n",
    "# # Réduction de 5 classes à 3 classes.\n",
    "# temp_train=[]\n",
    "# for el in y_train :\n",
    "#   if el<= 1 :\n",
    "#     temp_train.append(0)\n",
    "#   elif el == 2 :\n",
    "#     temp_train.append(1)\n",
    "#   else :\n",
    "#     temp_train.append(2)\n",
    "# y_train=np.array(temp_train,dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2468,
     "status": "ok",
     "timestamp": 1616511253992,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "LSpWG5JPii2I"
   },
   "outputs": [],
   "source": [
    "tweet_reviews = pd.read_csv(root_folder + 'Sentiment/Entrainements des modeles/Tweets-Flight.csv')\n",
    "rev=np.array(tweet_reviews['text'])\n",
    "sentiment=tweet_reviews['airline_sentiment']\n",
    "y0=[]\n",
    "reviews0=[]\n",
    "\n",
    "# On re-equilible la base de données : on doit remove 5500 'neutral'\n",
    "n=9178-5500\n",
    "k=0\n",
    "\n",
    "for i in range(len(sentiment)):\n",
    "  el=sentiment[i]\n",
    "  if el=='negative' and k<n:\n",
    "    k+=1 \n",
    "    y0.append(0)\n",
    "    reviews0.append(rev[i])\n",
    "\n",
    "  if el=='neutral': \n",
    "    y0.append(1)\n",
    "    reviews0.append(rev[i])\n",
    "\n",
    "  if el=='positive': \n",
    "    y0.append(2)\n",
    "    reviews0.append(rev[i])\n",
    "\n",
    "y_train=np.array(y0,dtype='float32')\n",
    "X_train=np.array(reviews0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHR3zv8Zabwl"
   },
   "source": [
    "Preprocess training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 17510,
     "status": "ok",
     "timestamp": 1616511275366,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "5rUl3SiZaaZz"
   },
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         binary=True,\n",
    "                         smooth_idf=False)\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btod0mXpb2T3"
   },
   "source": [
    "Fit a Mutinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10651,
     "status": "ok",
     "timestamp": 1616511275367,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "9hgf_W6Mb1tc",
    "outputId": "1b466df8-9c12-4e18-d2d8-58046533acb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha = 0.3\n",
    "multi_nb_model = MultinomialNB(alpha=best_alpha)\n",
    "multi_nb_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIErXS0fXZpz"
   },
   "source": [
    "Load tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7968,
     "status": "ok",
     "timestamp": 1616511290209,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "VwmJcLoUwL73"
   },
   "outputs": [],
   "source": [
    "tweets_filename = 'stream_tweets_Week4_181k'\n",
    "tweets = dataframe_from_mult_files([root_folder + 'Tweets/' + tweets_filename + '.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vg9i5Vtcdvbx"
   },
   "source": [
    "Preprocess tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 545889,
     "status": "ok",
     "timestamp": 1616511833064,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "qx7qrB4zdgz_"
   },
   "outputs": [],
   "source": [
    "tweets_preprocessed = np.array([text_preprocessing(text) for text in tweets['text']])\n",
    "tweets_tfidf = tf_idf.transform(tweets_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzmxSSQXc625"
   },
   "source": [
    "Get predictions from Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 536136,
     "status": "ok",
     "timestamp": 1616511833068,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "w5d0-4Vsc390"
   },
   "outputs": [],
   "source": [
    "sentiments = multi_nb_model.predict_proba(tweets_tfidf).argmax(1) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW-4szGDkiYc"
   },
   "source": [
    "Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1616511841722,
     "user": {
      "displayName": "Léo Gonçalves",
      "photoUrl": "",
      "userId": "09555909323570921688"
     },
     "user_tz": -60
    },
    "id": "JwSeUHCL80CC"
   },
   "outputs": [],
   "source": [
    "save_sentiments(\n",
    "    sentiments = sentiments,\n",
    "    folder_name = root_folder + 'Sentiment/Génération des résultats/Sentiments/',\n",
    "    tweets_filename = tweets_filename,\n",
    "    model_name = 'Naive Bayes'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOKsCILX52v0GAxqJf+5cn1",
   "collapsed_sections": [],
   "name": "Multinomial Naive Bayes.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
